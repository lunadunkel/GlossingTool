# Glossing Tool

Приложение для глоссирования текстов на нивхском языке с использованием автоматической морфологической сегментации.

## Описание

Приложение включает в себя четыре этапа для последовательной разметки

1. Ввод своего предложения или выбор из тестовой демо-версии репозитория (включает в себя один маленький текст)
2. Автоматическая морфемная сегментация с возможностью ручной корректировки
3. Подстановка всех известных глосс к морфемам, где пользователь может выбрать наиболее подходящую
4. Финальный результат с возможностью копирования отдельных сегментов или сразу же всего результата (+ возможность пользователем подставить перевод)

## Архитектура проекта

```
├── backend/
│   ├── src/
│   │   ├── core/              # Базовые классы и конфигурация
│   │   ├── models/            # Нейросетевые модели
│   │   ├── training/          # Обучение модели(ей) (в перспективе)
│   │   ├── inference/         # Инференс
│   │   ├── pipelines/         # Пайплайны обработки данных
│   │   └── tokenization/      # Токенизация
│   ├── tests/                 # Юнит-тесты
│   ├── vocabularies/          # Словари
│   ├── main.py                # FastAPI сервер
│   └── requirements.txt       # Зависимости
│
├── frontend/
│   ├── index.html             # Главная страница
│   ├── script.js              # Код фронта
│   └── styles.css             # Стили
│
└── yaml_configs/              # Конфигурации моделей
```

## Быстрый старт

### Установка

1. **Клонировать репозиторий**
2. **Создать venv** 
2. **Установить зависимости**
3. **Настроить переменные окружения** (опционально, только для обучения):

Создайте файл `backend/.env`:
```env
GITHUB_TOKEN=your_github_token
USER=your_username
REPO=repository_name
REPO_USER=repo_owner
```

### Запуск приложения

**Для (более-менее) гарантированного запуска (в том числе на Windows)**
```bash
python -X utf8 -m uvicorn backend.main:app --host 0.0.0.0 --port 8000 --reload
```

**Открыть локальный хост в браузере:**
```
http://localhost:8000
```

### API-запросы (также можно посмотреть: http://localhost:8000/docs)

**Получить список предложений:**
```bash
GET http://localhost:8000/sentences
```

**Сегментировать текст:**
```bash
POST http://localhost:8000/segment
Content-Type: application/json

{
  "id": 1,
  "text": "слов-а с сегмент-аци-ей на нивх-ск-ом"
}
```

**Получить глоссы:**
```bash
POST http://localhost:8000/gloss
Content-Type: application/json

{
  "segmentation": ["сегмент", "аци", "я"]
}
```

## Обучение модели сегментации

Обучение доступно с помощью унифицированного скрипта со следующими параметрами:
1. `--config` – обязательный параметр, где прописаны все необходимые для обучения параметры
2. `--data_path` – необязательный параметр; при его отсутствии будет переход к использованию репозитория (должны быть заданы соответствующие параметры .env файла)
3. `--device` – необязательный параметр; тренировка на `cpu` или `cuda`

```bash
cd backend
python src/training/train_script.py \
    --config yaml_configs/CNN.yaml \
    --device cpu
```

## Формат входных данных

```
1>    текст на  оригинальном  языке через табуляцию (желательно) 
1<    текст на  таргет        языке  через табуляцию (желательно)
1=    Перевод может отсутствовать
```
**При этом важно**: все, что в скобках, данный пайплайн считает необязательными элементами; оно маскируется и не делится на сегменты

## Используемые технологии

**Backend:**
- FastAPI — веб-фреймворк
- PyTorch — глубокое обучение

**Frontend:**
- Vanilla JS
- HTML5/CSS

**Machine Learning:**
- CNN для сегментации